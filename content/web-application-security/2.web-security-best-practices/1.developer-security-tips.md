---
title: "Developer Security Tips"
metaTitle: "Developer Security Tips | DevBucket"
metaDescription: ""
---

## 10 Developer Security Tips
- Human Issue
  - Don't trust the user 
  - Validate and Sanitize
  - Limit Privileges
  - Encrypt Everything
  - Don't truct yourself

- Software Issue
  - Public vs Private Data
  - Field Verification
  - Authenticate every interaction
  - Beware leaks in console
  - Assume your walls will be breached

## Don't trust the user 
- The most dangerous component of any digital interaction apart from you, the developer, and the app, and the device, and the provider is the user. The human being left to their own devices quite literally to navigate and use whatever you've built. The user, no, let's put a human face on the people we build things for. The person touching, or swiping, or clicking, or typing, or otherwise using the thing you've built is the most likely trigger for something going wrong with that thing. And in more cases than I think any of us would be comfortable to admit that something going wrong constitutes a security risk. Don't trust the user is a common statement when discussing software security. And it's an important principle, but without proper context, a statement like that can easily feel and be interpreted as a devaluing of the person using their developed thing. And infantilization, a suggestion that the user is too inexperienced or uneducated or quite literally dumb to understand that they're not using things properly. That's not what don't trust the user means at all. Don't trust the user means the person using the thing you build does not know what you know about their usage and how that usage can lead to unexpected, unwanted, or even dangerous or harmful outcomes and they shouldn't have to. The person using your creation should not be able to do anything that leads them to unexpected, unwanted, dangerous, or harmful outcomes because the onus is not on your user to protect themselves. It's on you. So when we say don't trust the user, we mean given the opportunity the person using anything you build is likely to do something wrong or unexpected until they know how to do it right. And it's our responsibility as developers to ensure when they do, they're intercepted and guided towards the action they wanted to perform. Let me give you a real world example of this. Years ago I was asked to help with a news website that had a weird problem. When you visited the front page and clicked on the title of an article, the front page would reload instead of taking you to the article page. This was extra weird because the content management system being used created the front page and the links automatically. The writers had no way of setting the links or so I thought. Inspecting the HTML of the page I discovered each title was wrapped in a link element that was then wrapped around another link element. The outer link pointed at the article while the inner link pointed back to the front page. If you do this in HTML, nesting links inside other links, the innermost link is the one that works thus the navigation back to the front page. What I couldn't figure out was why this inner link was there to begin with. So I went back to see what was going on on the back end. And there I found the reason. When articles were put into the CMS, the editor, the human, added a link bank to the homepage around the title in the title field. And for some reason the CMS wasn't sanitizing this field so the HTML element wasn't stripped out. The intent of the editor was for readers to be able to click on the article title in the article pages to return to the front page, which I had to explain is an unexpected UX pattern and not a good design. But the bigger issue here was that the CMS allowed for HTML in the title field at all which could lead to far worse things than this double linking. The lesson, don't trust the user to not put HTML elements where they don't belong, or more practically, assume people will do surprising things like put HTML elements where they don't belong. And it's your responsibility as a developer to either prevent them from doing this or cleaning up the form input so they avoid unexpected behavior. Don't trust a user to fix your software. Fix it yourself.
  
## Validate and Sanitize
- The most immediate and most obvious incursion point for any digital app is an input field, typically a form of some sort. Here's an example. A standard form on website asks a visitor to enter their personnel, name, email address, website, and so on. What could possibly go wrong? Enter XSS short for cross-site scripting. This is when someone sends a script request to a website and attempt to execute that script even though it doesn't belong on the site. The classic example is sending a URI containing some inline JavaScript to trigger an alert like this. If this URI is stored in a database and then later displayed as is on the front end of a site, it will trigger an alert box showing up reading, hacked. Which is not great. Now, an unprompted alert like this is alarming, but relatively innocuous. Now imagine if instead of merely sending an alert the script executes some complex function to do something else, like execute a function on the server to allow access to the back end of the site or redirect input data to a new location or input malicious code into the browser for every future user. All these things are not only possible, they are common on the unsecured web. So what can we as developers do? We validate and sanitize every input to ensure only the stuff we want to get through, actually gets through. What does that mean? In many cases, errored code and an input field is just that, an error. Someone did some copy and paste and copied and pasted some extra code by accident. It happens to me all the time. To help the person using that input field, we can add validation to it. Validation is pattern matching via code. Input data must look like this, otherwise it's invalid and an error is triggered. A URL must take the form of a URL. An email address must take the form of an email address, et cetera. The validation you use depends on the field you're using and what type of data you're collecting. Here, for example, is HTML validation for a field meant to input a city name, followed by a comma, followed by a two letter country code. Input anything else, anything that doesn't match this pattern, and the form won't submit and the user gets an error message telling them this input doesn't match the pattern. And here's the important part. In most cases, you write your own custom validation functions so you get exactly the input you want and nothing else. On that note, it's necessary to do validation both on the user facing front end and on the server back end because any validation on the front end can be bypassed. I'll show you an example of that later in the course. Once the data has passed the validation stage, it's also necessary to sanitize the data. Sanitizing means literally cleaning the input of anything that shouldn't be there. Take our earlier example, the problem here is the input value contains some inline code that does not belong. Sanitizing this input means either transforming the inline code to something innocuous or stripping out the errand code. If you're working on the web with a URL input, there's a dedicated method available to you called encodeURI. Pass a value through this method and any errand or malicious scripts within the URL are escaped transformed into HTML entities. As you can see in this example, in the first part here we have a script tag. In the second part, all the HTML elements have been turned into HTML entities and cannot execute anywhere because it's now just text. For other types of input fields and other types of data, there are other methods. You can also make custom sanitation methods to yourself. Now, here's the thing. The type of sanitation you do in form input fields depends on the environment you're working in and the coding language you're using. If, for example, the input is being sent to a server running a database, input must be sanitized to eliminate any direct instructions to the database software. If the input sends information through a web protocol to a web server, the data must be sanitized to prevent either the browser or the server from executing commands in the input itself. And if the input is stored on the server to be output on the front end later, the data must be sanitized to prevent the future output from containing malicious or unintended code. As with validation, it's best practice to sanitize the data both on the front end and on the receiving backend. So both as the data enters your system and as it leaves it. If you're using a framework or a templating system, frontend output is typically sanitized by default. If not, build your own sanitation functions to ensure what is sent to the frontend is nice and clean.
	
## Limit Privileges
-Controlling what people can and cannot do in any situation is vital to security. You control who has a key to your home, who can access your bank account and medical information, probably even who has access to your email address and phone number. Limiting access is the name of the game when it comes to any kind of development. To spell it out in clear text, give people as limited access as possible so they can do what they're there to do without being able to do anything else. There are two main reasons for limiting privileges. Preventing trusted people from accidentally doing something they weren't supposed to do or to do something they didn't know they could do, like reconfiguring core settings or adding or deleting users, and to limit what a malicious user can do if they gain access to an account. This is a vital principle anytime you're building an application with settings. Figuring out what capabilities are available to a person using the application, and then what capabilities should be available to different types of users and use scenarios is key to developing a secure application. The most straightforward way of doing this is to create a list of all possible functions within the app, every single thing someone with full access can do. Once you have that list, identify the user types or user roles you'll need in the application. This can be just a few or a long list, depending on what capabilities are available and who should have access to them. Based on these two lists, you can now create a structured access scheme for your application. Let's take a web publishing application as an example. Users have access to public information and the capability of editing their profile information, nothing else. Authors have all user rights plus the capability to create, edit, and delete their own content until it has been published. Editors have all author rights plus the capability to edit content made by others. Publishers have all editor rights plus the capability to publish and delete content made by others. And finally, administrators have access to everything including adding and removing other users. When adding a new person to the system, default them to the lowest possible access level and privileges, in this case, the user level. Then, if they need more functionality, only grant them what they require and nothing else. Additionally, if someone will do mostly publishing work but occasionally also manages users, create two accounts for them, a publisher account for daily use, and a special admin account only for when they need admin functionality. For most applications, tiered privileges like this are sufficient. For advanced applications or applications that can be used in many different ways, adding the ability to create new custom user roles with specific privileges, or even customizing privileges down to the individual user is recommended.
	
## Encrypt Everything
- I remember sending client files over an unencrypted FTP connection in the early days of the modern web, and I cringe. Anyone on the network listening in, either on my end, at the ISP, or at the client end, or anywhere in between would be able to not only see everything I sent over that connection, including my username, and password, and the files themselves, but also copy it all to their computer. Thankfully, unencrypted FTP is not in common use anymore in large part because the deployment methods we use are far more advanced, and those more advanced methods include end-to-end encryption. If you ask me for one thing you can do right now to secure the things you build, the systems you build them with, yourself, and the people around you my answer is to encrypt all the things. Every time you transfer any information over any network ensure it's done over an encrypted connection. That goes for deploying production code, committing files to a hosted version control system, accessing cloud storage, logging onto any online service, paying your credit card bills online, logging into your email account, literally anything you do that involves some form of connection with another computer over a network connected to the internet must be encrypted. Thankfully, the HTTP/2 protocol requires encryption via HTTPS, so most modern web services and web browsers enforce encryption at the base layer. And because of this you can now get free SSL certificates for any website and any web service through services like Let's Encrypt. And I know you're wondering about this, so here's the answer to the question you were about to ask. Free SSL certificates and expensive SSL certificates are the same technology in different product packaging. In most cases, hosting companies that sell expensive SSL certificates are selling you the internet security equivalent of bottled, clean tap water. You don't need the expensive version because it's the same as the free version. And yes, this is a statement with modifications. For enterprise security and specific use cases, a more advanced, signed, and certified SSL certificate is necessary mostly for documentation and legal purposes, but the SSL underneath, the technology layer, the water if you will, is the same whether you pay for it or not. In other words, there is no excuse for not having SSL. So add that S to your HTTP right now because encryption only happens if you the developer specifically do your work with encryption in mind. That means enforcing encryption protocols on every user interaction, blocking transfer of information if the encryption does not work or fails or is broken, and providing clear and followable steps for users and administrators to reestablish encryption when it fails so they don't try to work around things by transferring data over an unencrypted connection. This is going to sound alarmist so I want you to understand, I say this because I've seen some things. Assume someone, probably a bot, is watching every bit of data flowing from your device onto the internet. If it's not encrypted, someone has access to it. And even if you think your data is uninteresting and innocuous and you don't have anything to hide, encrypt it because our data rights are interdependent and encryption is the first line of defense when it comes to data theft and exploitation. Bottom line, encrypt all the things.
	
## Don't truct yourself
- Did you lock the door? Did you turn off the stove before you left the house? Did you close the fridge? Is the light still on? It's fascinating how once doing something becomes routine, our memory of having done it becomes fleeting to the point where we often can't remember at all, and then on the rare occasion when you actually forgot to do something, the only way you'll find out is by going back and checking. When it comes to development, we can't trust ourselves to make sure all security measures are addressed and that everything is working properly. There are many reasons for this of which two are the memory hole problem I just mentioned and the fact that we're way too close to our own creations to be impartial judges of their functionality. Here's the long and short of it. You, as a developer, can't trust yourself when it comes to the security of the things you develop, and you can't rely on yourself to test the things you develop either to make sure they're secure because you are not your user. That's a hard pill to swallow, at least until you realize accepting this reality can make your work as a developer a lot easier and less stressful. Start off every project with accepting that making mistakes and learning from them is how you got where you are today, and that you will continue to grow in your skills only by making mistakes and learning from them again. That way, you can fast-track your own growth and the success of every project you work on by enlisting help to find the bugs you've overlooked. Knowing those bugs, you can not only fix them, but learn how and where they came from, how they got there, and how to prevent them from coming back. There are two paths to employing assistance and testing your projects for security and other issues. Automated testing and human usability testing. I recommend using both. Automated testing, more specifically unit testing, is a great way of continuously challenging your work against a set of test criteria so you know the things you're developing produce the outcomes you intend. A unit test for an email form input field can look like this. A script submits a bunch of valid and invalid email addresses to a form field and monitors the results. Only the valid ones should pass and the invalid ones should fail. If not, something is not right in your code and you need to fix it. You can find community managed unit test data for almost any type of data input on GitHub and other free resources. I recommend building unit tests into your standard development process and running them as soon as you start implementing new features. That way, you know right away if you've left a security hole somewhere or if your feature is not working properly. It also helps you catch errors as they're introduced, so you can deal with them immediately rather than having to go back and debug something when your project nears completion. The good news is for every programming language and every framework and build process and environment you may find yourself using, there are robust unit testing suites available so you don't have to build one from scratch. Just plug one in and get started. When your project is at a stage where someone can start using it, engage people in user testing. I recommend including people who have knowledge about how to uncover security issues, ideally a security expert or in a pinch, another developer, and also normal users. During testing, have them use any feature where there may be a security issue with special focus on inputs and other information transactions and keep a log of every action they do. For a web application, a bare-bones way of doing this is to have the application log all data to the console, get the tester to work on the computer, and then open the console in a separate window on a screen you can see. That way, you can see what data they're inputting into the application and how that data is handled by your application. And here's why. Once I found I had overlooked proper sanitation in a form when a tester copied some content from a website featuring code examples and paste it in a JavaScript function in a long text field, the way I'd set up that form, the JavaScript was entered as JavaScript in the database and would have rendered on the front-end as part of the website. I'd omitted the escape method in my input field as an oversight, and that particular scenario of copying and pasting code was so far outside the intended use of the website I didn't add it to my unit tests. Had it not been for this human being stuffing JavaScript where it didn't belong, I would've shipped a website with a major security flaw. That's why I don't trust myself, and instead trust my test process.


## Public vs Private Data
- Consider this form. It asks you for your first and last name, your email address, your website, your phone number, your home address, your username, your password, your bank account information, your credit card number expiration date and secret code, your birthdate, your personal or social security number, your mother's maiden name, and the name of your first pet. Now, these are all data you will have filled into an online form at some point, but if you encountered an online form requesting all of this data at the same time, I have reason to believe you'd have serious reservations about filling it out. Let's discuss why. In computing, we deal with public and private data. In simple terms, public data is data which can be accessed through some form of request without prior authorization, while private data can only be accessed with authorization. When we develop tools to collect data, in almost every case that data becomes available to someone as long as they have sufficient authorization. That also means if an unauthorized individual is able to obtain sufficient authorization, they will gain access to all of that data, including private data. For this reason and many others, it's a good rule of thumb to think of any data available over the internet as eventually compromised data. We have to assume that at some point, the data will be accessed by someone who should not have access to it, either intentionally or by accident. Knowing this, for each piece of data, consider whether it should be public or private, what access level each piece of data should require, and how best to protect the data from eventual compromisation. Here's a simple way of doing just that. First, grab each data point you're collecting through your app and place it in the first column of a spreadsheet. In the next column, identify what type of data this is. Text, a number, a phone number, an email address, a password, et cetera. In the third column, identify whether this data should be public or private by default. And in the fourth column for the private data, identify who should have access to it. Doing a content audit like this for every piece of data you collect helps you map out the level of security you need to build into your app. If you're working with a lot of private data, you may need to create several access levels depending on what data someone should have access to. And in some cases, you may need to encrypt the data, as in the case of passwords, or eliminate the data altogether and collect it temporarily for each interaction, like credit card information, for example. Clearly defining what data is public and private and how to protect that data is essential for building even the most basic application. The best place to start is to assume all data, even data meant for public consumption, needs some level of protection and make sure you always build in the option to switch public data to private or to delete all data temporarily or permanently.

## Field Verification
- We talked about verifying and sanitizing data in the previous chapter. I want to focus in on these processes in more detail, because there's some interesting challenges and pitfalls along the way, since most of the code that we're working with is publicly available code. The example I'm showing you here is of a website form, but the overhanging principles are universal to any digital data collection and storage system with a front end and a back end. This form is part of a larger app for displaying weather data for any location on earth, and the form input is the location itself. It has a very specific pattern required by the API we're sending information to. It has to be a city name, comma, and then no space, either a two-letter country key, or if in the case of the United States, a two-letter state key, followed by comma, followed by a two letter country key. This data is passed onto a weather API that returns weather data if the city exists. So if we want data, we have to follow this very specific pattern. To build this app and ensure that users are able to get at the weather information they want, I need to build in verification in this field so I know that they're inputting the correct data. And I will do that in three layers of verification. First, a client-side input verification layer in HTML. Then a client-side submit verification in JavaScript, and finally a server-side processing verification in whatever server runtime language we're working with. Let me show you what this looks like in the browser. I've opened up my developer tools here, so you can see the code we're working with. and when I scroll down, here we have an input field and inside the HTML for the input field is this attribute, pattern. And pattern holds this huge regex command. This is the pattern that we're trying to match against, and it basically says the first word can be a full word with spaces. Then there has to be a comma. Then there has to be a two-letter word from A to Z, or there can be a full word with spaces, comma, a two-letter word, comma, and another two-letter word. Anything else will not pass. Now let's look at what this HTML verification does for us. If I go up to the field and I type in a city, let's say burnaby,ca, so that's Burnaby in Canada, and I click Submit, the form works as expected, and down here in the console it says, Success! The input value is valid. So it's not actually doing anything, but that's how I output that things are working properly. Now let's break the format. I'll add in a space between the comma and then click Submit again. When I do, we get this warning; Please match the requested format. And this warning is generated by the browser because of this pattern attribute inside the HTML. That means because I'm not following this pattern, I can't pass information onto the next step and I'm stopped by the browser. It also means though, because the code is sitting in the browser, anyone who understands how this works can very simply bypass this verification. All I have to do is go into the developer tools and click Edit as HTML, and then delete the pattern attribute. Watch what happens when I do this. Remember how before I got a warning, I'll click Submit now and it works. But we get a new warning instead down here. This is the client-side submit verification built into the JavaScript. So what happens when you fill out the form is the information from the form is passed onto JavaScript, and in the JavaScript I've written another verification process to make sure that the code that is being submitted actually matches. To see that we can go into Sources, and scroll down to script.js, scroll down a little bit and here we have a validator function that has the same regex pattern. If the pattern is true, then we pass on. If not, we get an error message saying; The input value is invalid. Try again. But here again, we have a challenge because someone who understands how JavaScript and HTML works will be able to go into the developer tools just like I did here and remove this test as well. All I would have to do to make this work for me and be able to pass invalid information onto the server is to simply go into this code here and change this statement from return false to return true, and then just save it. Go up here and click Submit again and look; Success! The input value is valid. And we passed on information to the server. This is why you need to put server-side processing verification in place as well. Anything that happens on the browser end can and will be manipulated by someone with malicious intentions. Once the data reach the server, before the server does anything with the data, check to ensure it matches the required pattern. Now, in some cases, you have this capability, but in many cases you're dealing with an external API and you have no way of building data validation for that API. The good news is most APIs either have this capability built in already, or they will simply discard any request that doesn't match with their required pattern, and just return an error message. So as you build things out, make sure you know what happens when invalid data is sent because as you see, it can happen, and then see how the server responds and build in functionality to catch those responses and inform the user about what went wrong.

## Authenticate every interaction
- Authentication is a big enough subject that we have several courses on the topic. So rather than going to specifics, I'm going to focus on some general best practices, or rather one general best practice that will dramatically increase the security of anything you're developing. Authenticate every interaction. That sounds a bit extreme, doesn't it? Well, not if you stop and think about it. Consider your regular modern web-app as an example. Running with an SSL certificate over HTTPS, there's already a base level of authentication built in. The browser creates an authenticated session with the server, and all transactions are encrypted between the two. So even if someone just visits an application through a web browser or standalone app, they are, in a general and non-specific way, being authenticated. This base level of authentication ensures nobody can inject themselves into the conversation between the server and the person using the server, a so-called man-in-the-middle attack. It also ensures the person using the service is notified if the authentication breaks for any reason, making them aware any information they send and receive can be compromised until authentication is restored. The next level up for authentication is to have anyone using the application sign in. That doesn't mean they need to provide their personal information or even necessarily have an account. It means they need to provide some form of identifiable information to that session, so their unique interactions can be identified as such and can't bleed into other people's interactions. Above this level sits full user accounts with authorization levels. We touched on this briefly earlier. Every user account has a specified authorization level, providing access to specific data, functions and features, and these user accounts can be anonymous, pseudonymous or identifiable. Email accounts and social media accounts generally fall into this category. At the top level sits validated user accounts with signed authorization. These are user accounts tied to identified individuals. For example, enterprise service accounts, work accounts and so on. At this level, authentication is typically part of access control and has personal and or business impact. Now comes the interesting question. What level of authentication is necessary for your specific project? The answer may surprise you because it's a bit self-contradictory. You want as high a level of authentication as possible while at the same time collecting as little data about the person using the application as possible. Let's break that up into two principles. Principle one, access and power. Authentication for access to data, features and functionality needs to be in accordance with the power associated with the data, features and functionality. Accessing a website with reviews for streaming shows requires minimum authentication. Accessing an app where you can post content to social media requires a medium level of authentication. Accessing an app for a bank requires a very high level of authentication. Principle two, access and identity. Ask yourself this. Is identifying what user account accesses data or uses a feature or functionality mission critical to the app you're developing? And if so, is it necessary to know what real life person has access to that account? And if so, what information about that person is necessary for you to operate the app? In many cases, we collect way too much information about our users and subject them to possible future harm if our data is breached, and that only becomes apparent when we start asking these questions. When authenticating users, always aim for collecting as little personal information as possible to protect the identity of the person but enough information to be able to verify that the person is who they claim to be. It's a tough balancing act, but it's entirely possible to do. A good best practice here is actually to introduce two-factor authentication. That way you have two separate touchpoints for the real world person, and the identification of that person is left up to the providers of the services they use for 2FA, be that an email address or a cell phone number, or a standalone app.

## Beware leaks in console
- If you're like me, you log a lot of information to the console as you develop things. Not only is this an easy way of seeing what's going on with your application as you're developing it, but logging information is a vital debugging and even operations tool. However, the console can also become a major vector for leaking information if you're not careful. A few years ago, I visited a popular news site and discovered they were doing some beta testing in production because the console was full of information. Scrubbing through the output, I found a request URI for their internal rest API in plain text, complete with an authentication token. Having done this myself numerous times in development environments, I saw immediately, both what had happened and how easy it is to overlook such an error and I had to contact them and say, "Hey, you are leaking authenticated data here." To avoid accidentally leaking data into the console, here are some best practices for your development practice. Number one, use a code linter that flags any console logs with a warning. Number two, print protected data like keys, passwords, and authorization tokens to the console only if absolutely necessary as part of a debugging run. And number three, remove logs of private data immediately afterwards before moving onto your next task. Number four, use a build tool that strips out any console logs before deploying your code to production. And number five, test in production to make sure you're not leaking data into the console immediately after deploying your code. As before, modern development and build tools are your friends here, and most linters, optimizers, and minifars will warn you and strip out console log automatically with a simple setting.

## Assume your walls will be breached
- My favorite stage of any project is the premortem, where we explore in detail what can go wrong, how that going wrong would happen, what the consequences would be, and what can be done about it. The premortem is a vital part of project development, especially when it comes to security, and it's a surprisingly fun and interesting exercise to go through because it allows us to think about the work we're doing in a new and novel way. Here's how it works. At the beginning of your development process, and at several stages throughout the process, sit down with your team or your friends or your stakeholders and say, "Okay, it's four months from now. We've launched our project and a major newspaper's on the phone, asking for comments about the huge security breach we just experienced. What went wrong?" Just with that prompt alone, I'm sure you're able to come up with a long list of possible scenarios for the project you're working on right now or a project you worked on in the past. In fact, the more vivid the picture drawn of the response, there's a TV crew outside, law enforcement is on the way, the prime minister or president's office is on the line, the easier it is to come up with possible scenarios. The key to this exercise is to not limit yourself in the beginning. Blurt out any and all security breaches you can think of, and write them down. Keep doing this until no more ideas surface. You'll likely notice that once an idea goes onto a whiteboard or a sheet of paper, more ideas will bloom from that one idea. Once you have a list of possible security disasters, start addressing each of them in turn. Is this possible at all, and if not, why? How did this happen? Are there novel ways someone could get at this information? Could this be done even though we think it's not possible? And for each scenario, write down all the ways this breach could have taken place, and identify what paths or functions or methods an attacker could use to achieve this breach. Then, document how each breach can be prevented. What you get after this exercise is a long list of possible security breaches, along with a detailed documentation of where security risks are present in your project and how to address them. Doing a premortem at various stages throughout the development process keeps everyone focused on security and helps you surface issues as they arise and deal with them in a proactive manner before your project is launched to the world.

## Resources
- https//www.linkedin.com/learning/ten-security-tips-for-developers
